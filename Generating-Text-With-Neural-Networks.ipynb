{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd1cdf46",
   "metadata": {},
   "source": [
    "# Generating Text with Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab47b37",
   "metadata": {},
   "source": [
    "This program is desgined to train a model that can replicate text in the format of shakespeare. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70325e9",
   "metadata": {},
   "source": [
    "# Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b5298b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 10:49:50.778491: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://homl.info/shakespeare\n",
      "1115394/1115394 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "shakespeare_url = \"https://homl.info/shakespeare\"  # shortcut URL\n",
    "filepath = tf.keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc938f19",
   "metadata": {},
   "source": [
    "The section is importing the tensorflow library for the machine learning. The next line is defining the URL for thw text I want to work with. The third line is saving it and the fourth is opening it so that it can be read. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac39fd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n"
     ]
    }
   ],
   "source": [
    "print(shakespeare_text[:80]) # not relevant to machine learning but relevant to exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ce1260",
   "metadata": {},
   "source": [
    "This is printing the first 80 characters from the shakespeare_text file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de55b2aa",
   "metadata": {},
   "source": [
    "# Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05fbfd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 10:50:05.389154: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "text_vec_layer = tf.keras.layers.TextVectorization(split=\"character\",\n",
    "                                                   standardize=\"lower\")\n",
    "text_vec_layer.adapt([shakespeare_text])\n",
    "encoded = text_vec_layer([shakespeare_text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "573e8c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[21  7 10 ... 22 28 12]], shape=(1, 1115394), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(text_vec_layer([shakespeare_text]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709e8d73",
   "metadata": {},
   "source": [
    "Above the text is being converted to numbers so that it can be inputted in the ML model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcd3ce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded -= 2  # drop tokens 0 (pad) and 1 (unknown), which we will not use\n",
    "n_tokens = text_vec_layer.vocabulary_size() - 2  # number of distinct chars = 39\n",
    "dataset_size = len(encoded)  # total number of chars = 1,115,394"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4792bb",
   "metadata": {},
   "source": [
    "This is cleaning the data so that it is suitable for the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4c79b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 1115394\n"
     ]
    }
   ],
   "source": [
    "print(n_tokens, dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8571a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
    "    ds = ds.window(length + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda window_ds: window_ds.batch(length + 1))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(100_000, seed=seed)\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bd608b",
   "metadata": {},
   "source": [
    "This section is preparing the data for training. The model building stage is when layers are defined in order to outline the models structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba80acc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/emmamccargo/anaconda3/envs/Task4Environment/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "length = 100\n",
    "tf.random.set_seed(42)\n",
    "train_set = to_dataset(encoded[:1_000_000], length=length, shuffle=True,\n",
    "                       seed=42)\n",
    "valid_set = to_dataset(encoded[1_000_000:1_060_000], length=length)\n",
    "test_set = to_dataset(encoded[1_060_000:], length=length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfc4e36",
   "metadata": {},
   "source": [
    "In this section of code there are different stages happening. Train_set is training the data for the ML model. Vaild_set is validating the effectiiveness so that test_set can move onto the evaluation stage to assess how well the model is working. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d65051",
   "metadata": {},
   "source": [
    "# Building and Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f19e4cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 11:49:46.500148: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 67027 of 100000\n",
      "2023-12-01 11:49:50.691429: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  31247/Unknown - 3300s 105ms/step - loss: 1.4025 - accuracy: 0.5709"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31247/31247 [==============================] - 3385s 108ms/step - loss: 1.4025 - accuracy: 0.5709 - val_loss: 1.6163 - val_accuracy: 0.5311\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 12:46:09.328919: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 69234 of 100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "    1/31247 [..............................] - ETA: 126:27:21 - loss: 1.7032 - accuracy: 0.4906"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 12:46:13.778264: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31247/31247 [==============================] - ETA: 0s - loss: 1.3093 - accuracy: 0.5925"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31247/31247 [==============================] - 3277s 104ms/step - loss: 1.3093 - accuracy: 0.5925 - val_loss: 1.5969 - val_accuracy: 0.5355\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 13:40:46.646204: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 43863 of 100000\n",
      "2023-12-01 13:40:56.646305: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 94909 of 100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "    1/31247 [..............................] - ETA: 183:28:19 - loss: 1.6285 - accuracy: 0.5078"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 13:40:57.675029: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31247/31247 [==============================] - ETA: 0s - loss: 1.2915 - accuracy: 0.5961"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31247/31247 [==============================] - 3056s 97ms/step - loss: 1.2915 - accuracy: 0.5961 - val_loss: 1.5897 - val_accuracy: 0.5383\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 14:31:42.922700: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 60652 of 100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "    1/31247 [..............................] - ETA: 128:34:14 - loss: 1.6259 - accuracy: 0.5172"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 14:31:47.636207: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31247/31247 [==============================] - ETA: 0s - loss: 1.2813 - accuracy: 0.5983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_shakespeare_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31247/31247 [==============================] - 199335s 6s/step - loss: 1.2813 - accuracy: 0.5983 - val_loss: 1.5776 - val_accuracy: 0.5418\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 21:53:58.576070: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 30513 of 100000\n",
      "2023-12-03 21:54:08.571831: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 71386 of 100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "    1/31247 [..............................] - ETA: 226:41:18 - loss: 1.6166 - accuracy: 0.5013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 21:54:14.555839: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  616/31247 [..............................] - ETA: 54:39 - loss: 1.3273 - accuracy: 0.5866"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)  # extra code – ensures reproducibility on CPU\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True),\n",
    "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"my_shakespeare_model\", monitor=\"val_accuracy\", save_best_only=True)\n",
    "history = model.fit(train_set, validation_data=valid_set, epochs=10,\n",
    "                    callbacks=[model_ckpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0216893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_model = tf.keras.Sequential([\n",
    "    text_vec_layer,\n",
    "    tf.keras.layers.Lambda(lambda X: X - 2),  # no <PAD> or <UNK> tokens\n",
    "    model\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8927fee3",
   "metadata": {},
   "source": [
    "# Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0581742",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = shakespeare_model.predict([\"To be or not to b\"])[0, -1]\n",
    "y_pred = tf.argmax(y_proba)  # choose the most probable character ID\n",
    "text_vec_layer.get_vocabulary()[y_pred + 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9ba74e",
   "metadata": {},
   "source": [
    "This is allowing for predictions to be made through the already trained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b80ac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probas = tf.math.log([[0.5, 0.4, 0.1]])  # probas = 50%, 40%, and 10%\n",
    "tf.random.set_seed(42)\n",
    "tf.random.categorical(log_probas, num_samples=8)  # draw 8 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09755e3",
   "metadata": {},
   "source": [
    "I think here the mathematical feature log is being used to calculate probabilites to produce samples of text. This is a confusing step specifically for those without a mathematical background. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09519ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(text, temperature=1):\n",
    "    y_proba = shakespeare_model.predict([text])[0, -1:]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1)[0, 0]\n",
    "    return text_vec_layer.get_vocabulary()[char_id + 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2005314",
   "metadata": {},
   "source": [
    "This is used to provide a random text output when given a random input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b91b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_text(text, n_chars=50, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12a05e6",
   "metadata": {},
   "source": [
    "This should produce longer random text outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9085f1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code – ensures reproducibility on CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc5864a",
   "metadata": {},
   "source": [
    "This is ensuring reproducibility across the model making it easier to evaulate and fix any issues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9632ff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extend_text(\"To be or not to be\", temperature=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d1a893",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extend_text(\"To be or not to be\", temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6803df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extend_text(\"To be or not to be\", temperature=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50763bf0",
   "metadata": {},
   "source": [
    "It could be interesting to use this model for different languages and historical documents. This could be used for educational purposes to learn about a different culture or time period. To alter this model the 'shakespeare_text' dataset would need to be replaced with another dataset that had a similar format. Ethical concerns include misuse of the model to produce something either harmful or culturally inappropriate, there are also copyright concerns around the use of different datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6042fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
