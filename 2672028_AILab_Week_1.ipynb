{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "438dac4b",
   "metadata": {},
   "source": [
    "# Week 1: Getting started with Anaconda, Jupyter Notebook and Python\n",
    "\n",
    "Exercises to familiarise myself with Jupyter Notebook and its relationship to Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c445f8ab",
   "metadata": {},
   "source": [
    "### a) I choose this course beacause I am very interested in the subject area and I think that it could benefit me in the future due to it being a field increasing in popularity and relevance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e79bdb8",
   "metadata": {},
   "source": [
    "### b) I have no experience in AI or Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc592ba3",
   "metadata": {},
   "source": [
    "### c) I expect to learn\n",
    "    - The basics of python\n",
    "    - The developments occuring in AI\n",
    "    - Ethics surround AI\n",
    "    - More details about machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bbb9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "greeting = (\"Have a good day!\")\n",
    "\n",
    "print (greeting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2c302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import *\n",
    "\n",
    "YouTubeVideo(\"472AnCrHYVs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cead49",
   "metadata": {},
   "source": [
    "# Week 2: Exploring Data in Multiple Ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ef4c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bab1863",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Image (\"picture1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e83ace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1a641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio (\"audio1.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b239226",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio (\"audio2.ogg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b31da7d",
   "metadata": {},
   "source": [
    "#### This file is licensed under the Creative Commons Attribution-Share Alike 3.0 Unported license.\n",
    "    You are free: \n",
    "        •\tto share – to copy, distribute and transmit the work\n",
    "        •\tto remix – to adapt the work\n",
    "    Under the following conditions: \n",
    "        •\tattribution – You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\n",
    "        •\tshare alike – If you remix, transform, or build upon the material, you must distribute your contributions under the same or compatible license as the original.\n",
    "\n",
    "The original ogg file was found at the url: \n",
    "https://en.wikipedia.org/wiki/File:GoldbergVariations_MehmetOkonsar-1of3_Var1to10.ogg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a45f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "test_picture = pyplot.imread(\"picture1.jpg\")\n",
    "print(\"Numpy array of the image is: \", test_picture)\n",
    "pyplot.imshow(test_picture)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42193e86",
   "metadata": {},
   "source": [
    "#### When using the 'pyplot.imshow(test_picture_filtered)' command the image is displayed more as points on a graph rather than as the actual image shown above. We assume this is due to the numbers being divided moaving them smaller and less visable as an image and more as points on the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60bcc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "dir(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b873677",
   "metadata": {},
   "source": [
    "#### I chose load_wine because I like wine and load_diabetes as I don't know much about the condition so wanted to know more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eda5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "wine_data = datasets.load_wine()\n",
    "\n",
    "print(wine_data.target_names)\n",
    "\n",
    "wine_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a4a8cf",
   "metadata": {},
   "source": [
    "#### My dataset has 13 features. By running the command wine_data.target_names I believe that this dataset is aiming to classify the different wines into categories. However, from this command alone I am not able to tell anything further about those categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1cd4a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "load_diabetes = datasets.load_diabetes()\n",
    "\n",
    "print(load_diabetes.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ab9c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas\n",
    "\n",
    "wine_data = datasets.load_wine()\n",
    "\n",
    "wine_dataframe = pandas.DataFrame(data=wine_data['data'], columns=wine_data['feature_names'])\n",
    "\n",
    "wine_dataframe.head()\n",
    "wine_dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4586d6e",
   "metadata": {},
   "source": [
    "#### I think that these commands take the information from the dataset and display them in a table. This makes the information easier to read. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2973c0da",
   "metadata": {},
   "source": [
    "# Machine Learning by Example: from Start to End"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7332090f",
   "metadata": {},
   "source": [
    "### Task 1-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19f4266",
   "metadata": {},
   "source": [
    "[Diagram](https://www.google.com/url?sa=i&url=http%3A%2F%2Fwww.theobjects.com%2Fdragonfly%2Fdfhelp%2F2020-1%2FContent%2FArtificial%2520Intelligence%2FDeep%2520Learning%2520Tool%2FWorkflow%2520and%2520Data%2520Preparation.htm&psig=AOvVaw0S_PEl57ADubs4tyxMe4oM&ust=1700662693862000&source=images&cd=vfe&opi=89978449&ved=0CBIQjRxqFwoTCMjB76-k1YIDFQAAAAAdAAAAABAl)\n",
    "\n",
    "The example in lecture 3 uses spam or a new email as an example for data. Using this model and the example of spam the new data would be spam, the learning algoritm would learn identifiable features of spam, the model would then flag for spam and the model would output a response to avoid spam. The model can then be tested on new emails.\n",
    "\n",
    "This example is a beginner friendly way to explain the complicated workflow. To try to describe this to a museum curator you could use the example of a search on their website as new data, that the learning algoritm would be programmed to find them collections related to their search, then the model use key words to direct them to the right place and the response would be a webpage of a collection related to their search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77059ff",
   "metadata": {},
   "source": [
    "## Ways to improve your notebook that could engage the wider audience with your machine learning code.\n",
    "\n",
    "1. Including some output can provide immediate examples of work however too much output can cause mess and be overwhelming. \n",
    "2. Clear documentation in a markdown cell that includes the purpose of the notebook, a detailed description of what you done and outline any problems that might be faced. \n",
    "3. Ensure that your notebook is in an order that is clear to follow so it is easier to understand why you have taken the next step. \n",
    "4. Embed images, audio and videos to make your notebook more exciting and engaging. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce9b637",
   "metadata": {},
   "source": [
    "### Task 1-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f2972f",
   "metadata": {},
   "source": [
    "### Understand how framing the problem affects data selection\n",
    "\n",
    "Clearly stating the problem in your markdown cell is important for clarity. Both for future readers and for yourself at a later date. Outlining the problem straight away allows for readers to understand the steps taken to reach the end goal. \n",
    "\n",
    "It helps make sense of your notebook and also helps should you need to replicate areas of your notebook in the future. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f162011c",
   "metadata": {},
   "source": [
    "### How to select your algorithm\n",
    "\n",
    "For predicting median housing prices regression machine learning would be a better fit. This is because the main goal of regression ML is to estimate a mapping function based on the input and output variables. It can predict the values of depndant variables based on the values of an independant variable. Therefore it can make a prediction regarding house prices when given data about different factors. \n",
    "\n",
    "For handwritten digit recognition classification would be a better fit. This is because from imput variables it can create output variables that groups data into similar subgroups. This is better for handwritten digit recognition as there would be clear categories of similar data that each input could be assigned to. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f491d47a",
   "metadata": {},
   "source": [
    "### Before Data Collection\n",
    "\n",
    "Economy of the country and location within that country, range of properties in an area, size/age of properties, size of area and prices that a range of properties have sold for. \n",
    "\n",
    "A range of factors related to geographical and cultural differences could bias the data. Some examples include: societal norms, education levels and preferences between different cultural groups. In terms of geography, climate, urbaan vs. rural and a need to be close to transport links could affect the results collected. The data could become biased if one of these factors heavily influenced the collection hinting to a higher prevelance of one factor than true. Missing data also could play a part. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfa4f0b",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7a4016",
   "metadata": {},
   "source": [
    "### Task 2-3\n",
    "\n",
    "figsize=(12, 8)\n",
    "\n",
    "They split the dataset into two subsets, a training set containing images use for training machine learning models and a test set used for testing the trained models.  \n",
    "\n",
    "We think they done this to create a standardised approach. A lot of Data scientists use the the MNIST dataset to tain new algorithms.\n",
    "\n",
    "Yes. It creates a benchmark for ML models improving replicability. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415eb903",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be3f177",
   "metadata": {},
   "source": [
    "### Task 3-1\n",
    "\n",
    "\n",
    "A stratified sample based on median income is reasonable for the following reasons. As it is a method where researchers have divided into relatively similar subpopulations. As it ensures that specific subgroups are present in a sample. It helps to obtain precise estimates of each group’s characteristics. and it helps with the analysis of the differences between each subgroup as it is simplified. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcd792b",
   "metadata": {},
   "source": [
    "### Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a262b9a5",
   "metadata": {},
   "source": [
    "There are 4089 missing for the number of `total_bedrooms'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3487bf71",
   "metadata": {},
   "source": [
    "### Task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef50d26",
   "metadata": {},
   "source": [
    "### Task 5-1\n",
    "\n",
    "1. If using your own data you would need to ensure that it was compatible with the workflow already in place. This would take place in the data preprocessing stage where the data would need to be analysed to ensure that there was no errors such as missing values and formatting issues. If using Images you would need to ensure that the code was compatible with images not just values.\n",
    "    If you were to change your model then you would need to retrain your model to fit with the data (example: from sklearn.linear_model import LinearRegression). Adjustments would have to be made to the code should you change you scaling method to ensure that the new method would align with the requirements of the model trained (example: from sklearn.preprocessing import MinMaxScaler section). If you were to change your approach to handling missing data then adjustments would have to be made to the code responsible for this (example: housing_option1.dropna(subset=[\"total_bedrooms\"], inplace=True). \n",
    "    Cross-validation is significant as it checks the performance of your model by splitting the datasets into different subsets. It provides an evaluation regarding the performance of the model in question while assessing if the model is suitable for the specific dataset. \n",
    "2. The lowest training loss score I could achieve was  0.499. I had 3 hidden layers with 3 nodes in one, 2 nodes in the other and 4 in the final. This gave me 000,433 epochs on my best model.\n",
    "3. Some nodes cause the ornage and blue colours to meet at a harsh straight line in the middle with distictive colours on each side. Other nodes have paler colours and meet with squiggly lines at various points of the screen. On some nodes one colour can dominate more strongly than the other colour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b206eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
